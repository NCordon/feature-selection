\documentclass[a4paper,11pt]{article}
% Símbolo del euro
\usepackage[gen]{eurosym}
% Codificación
\usepackage[utf8]{inputenc}
% Idioma
\usepackage[spanish]{babel} % English language/hyphenation
\selectlanguage{spanish}
% Hay que pelearse con babel-spanish para el alineamiento del punto decimal
\decimalpoint
\usepackage{dcolumn}
\newcolumntype{d}[1]{D{.}{\esperiod}{#1}}
\makeatletter
\addto\shorthandsspanish{\let\esperiod\es@period@code}
\makeatother

\usepackage[usenames,dvipsnames]{color} % Coloring code

\usepackage{longtable}
\usepackage{tabu}
\usepackage{supertabular}

\usepackage{multicol}
\newsavebox\ltmcbox

% Para algoritmos
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm}
% Para matrices
\usepackage{amsmath}

% Símbolos matemáticos
\usepackage{amssymb}
\let\oldemptyset\emptyset
\let\emptyset\varnothing

% Hipervínculos
\usepackage{url}

\usepackage[section]{placeins} % Para gráficas en su sección.
\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\newenvironment{allintypewriter}{\ttfamily}{\par}
\setlength{\parindent}{0pt}
\parskip=8pt
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default


% Imágenes
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{wrapfig} % Allows in-line images

% Referencias
\usepackage{fncylab}
\labelformat{figure}{\textit{\figurename\space #1}}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

%Basado en: http://en.wikibooks.org/wiki/LaTeX/Theorems
\usepackage{amsthm}
\newtheorem*{mydef}{Definición}
\newtheorem{mydefn}{Definición}
\newtheorem{theorem}{Teorema}
\everymath{\displaystyle} % Displaystyle por defecto



% To change level of indentation
\newenvironment{answer}{%
\begin{list}{}{%
}%
\item[]}{\end{list}}


\makeatletter
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography
\newcommand{\imagent}[4]{
  \begin{wrapfigure}{#4}{0.7\textwidth}
    \begin{center}
    \includegraphics[width=0.7\textwidth]{#1}
    \end{center}
    \caption{#3}
    \label{#4}
  \end{wrapfigure}
}

\newcommand{\imagen}[4]{
  \begin{minipage}{\linewidth}
    \centering
    \includegraphics[width=#4\textwidth]{#1}
    \captionof{figure}{#2}
    \label{#3}
  \end{minipage} 
}

%Customize enumerate tag
\usepackage{enumitem}
%Sections don't get numbered
%\setcounter{secnumdepth}{0}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
% Modified by: NCordon (https://github.com/NCordon)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title_page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------
\textsc{\LARGE Universidad de Granada}\\[1.5cm]
\textsc{\Large Metaheaurísticas}\\[0.5cm] 

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------
\bigskip
\HRule \\[0.4cm]
{ \huge \bfseries Práctica I}\\[0.4cm] % Title of your document
{ \huge \bfseries Selección de características}\\
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{\textwidth}
\begin{center} \large
\emph{Búsqueda Local,esquema de primer mejor}\\
\emph{Enfriamiento Simulado}\\
\emph{Búsqueda tabú básica}\\
\emph{Búsqueda tabú extendida}\\
\end{center}
\end{minipage}

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\begin{center}
\includegraphics[width=8cm]{../data/ugr.jpg}
\end{center}
%----------------------------------------------------------------------------------------

\begin{minipage}{\textwidth}
\begin{center} \large
Ignacio Cordón Castillo, 25352973G\\
\url{nachocordon@correo.ugr.es}\\
\ \\
$4^{\circ}$ Doble Grado Matemáticas Informática\\
Grupo Prácticas Viernes
\end{center}
\end{minipage}


\vspace{\fill}% Fill the rest of the page with whitespace
\large\today
\end{titlepage}  

\newpage
\tableofcontents
\newpage
% Examples of inclussion of images
%\imagent{ugr.jpg}{Logo de prueba}{ugr}
%\imagen{ugr.jpg}{Logo de prueba}{ugr2}{size relative to the \textwidth}

\section{Descripción del problema}
Dado un \textit{dataset} de instancias ya clasificadas, con una serie de atributos, se pretende comparar las distintas 
metaheaurísticas disponibles para comprobar cuál produce el conjunto de atributos que sirven para obtener una mayor 
tasa de clasificación (número de instancias bien clasificadas sobre el total) usando un clasificador de instancias.

Se considera la tasa de clasificación en el problema usando un clasificador \textit{3-knn} leaving one-out. Para cada 
instancia de un conjunto, toma las 3 más cercanas usando la distancia euclídea entre sus atributos, y etiqueta la nueva
instancia en función de la etiqueta mayoritaria de entre esas tres. Se efectúan 5 particiones al 50\% estratificadas
por clase en \textit{train - test}, de modo que la metaheurística proporcionará un conjunto de atributos para el conjunto de
entrenamiento, y se calculará la tasa de clasificación que produce sobre el conjunto de prueba para el \textit{3-knn} dicho
conjunto de atributos. El proceso se repite intercambiando los conjuntos de entrenamiento y de test. La calidad de la 
metaheaurística/algoritmo se calculará como la media de todas las tasas de clasificación obtenidas sobre el conjunto test
(10 en total). Otras medidas que se tendrán en cuenta a la hora de evaluar la bondad de un algoritmo empleado serán:
\begin{itemize}
 \item Tasa de reducción: Número de características que contiene seleccionadas la máscara sobre el total que podía 
 seleccionar. 
 \item Tiempo de ejecución: Tiempo en segundos que tarda el algoritmo en devolver un conjunto de características.
\end{itemize}


La tasa de clasificación del clasificador se mide (en tanto por uno) como: $$tasa\: clasificacion = \frac{instancias\: 
bien\: clasificadas}{total\: instancias}$$

La representación usada es la binaria (1 o 0 por característica), donde tenemos un vector de tamaño $n$, con $n$ el número 
de atributos (exceptuando la clase), y la metaheaurística/algoritmo ha seleccionado el atributo si y solo si lo ha marcado 
a 1. A una representación de esta forma, la denominamos máscara: $$ mask =\begin{matrix} (0 & 1\ldots 1 & 1 & 0\ldots) 
\end{matrix}$$


\section{Descripción elementos comunes de los algoritmos}
Los algoritmos considerados tienen las siguientes componentes:

\begin{itemize} 
\item Esquema de representación: se usarán máscaras, sucesiones de unos y ceros de tanta longitud como atributos haya,
exceptuando la clase, donde un 1 en la posición $i-$ésima indica que esa característica se ha escogido, y un $0$ que no.
\item Función objetivo: la función a maximizar será la tasa de clasificación explicada arriba usando el clasificador
3-knn con la selección de características indicada por la máscara.

\small\texttt{\input{tasa_clasificacion}}

\item Generación de solución inicial: en el caso del 3-NN, la solución inicial es la máscara trivial (todos los valores a 1).
En SFS, la solución inicial es la máscara nula (todos los valores a 0). En el resto de algoritmos, la solución inicial se
generará de manera aleatoria (depende por tanto de la semilla empleada en cada aplicación del algoritmo).
\item Esquema de generación de vecinos: En las metaheaurísticas empleadas (Búsqueda Local, Enfriamiento Simulado, Búsqueda
Tabú, Búsqueda Tabú básica y extendida) se generan los vecinos cambiando el estado de la característica $i-$ésima de
escogido a no escogido y viceversa.

\small\texttt{\input{flip}}

\item Criterio de aceptación de solución: se considera una función mejor cuando aumenta la función objetivo (tasa de 
clasificación del 3-knn para la máscara dada por esa solución).
\item Criterio de parada: el criterio de parada común en las 4 metaheaurísticas empleadas es la evaluación de 15000 posibles
soluciones. Como criterios particulares se contemplan las siguientes condiciones de parada:
  \begin{itemize}
    \item Búsqueda local: se parará la generación de vecinos cuando no se halle mejora en todo un entorno.
    \item Enfriamiento simulado: se parará la ejecución cuando la temperatura actual se quede por debajo de la escogida
    inicialmente.
  \end{itemize}
  
\item Número de evaluaciones máximas: $tope_{evs}$ queda fijado en todos los algoritmos a 15000.

\end{itemize}

\section{Profundización en los algoritmos}
\subsection{Búsqueda local}

\small{\texttt{\input{BL}}}
\normalsize

\subsection{Enfriamiento Simulado}

\small{\texttt{\input{ES}}}
\normalsize\\

En el caso de este problema $tope_{vecinos} = 10\cdot n$ donde $n$ es el tamaño de la máscara.
Y $tope_{exitosos}$ queda fijado a  $0.1\cdot tope_{vecinos}$

La temperatura inicial se toma como $T_{0}=\frac{\mu \cdot tasa(mascara\:inicial)}{-ln(\phi)}$
\\donde $\mu = 0.3$ y $\phi=0.3$. 
\ \\ \ \\
Es decir, un 30\% de probabilidad de que la solución escogida sea
un 30\% peor que la inicial.

La temperatura final se toma como $T_f = 10^{-3}$. En caso de ser esta temperatura mayor que la inicial,
se hará $T_f = 10^{-3k}$ con $k$ el primer natural para el que $t_i < t_f$

El esquema de enfriamiento de Cauchy usado ha sido: 
$$T_{actual+1} = \frac{T_{actual}}{1+T_{actual}\cdot \frac{T_0 - T_f}{M\cdot T_0\cdot T_f}}$$
donde $tope_{enfriamientos}=M = 15000/max_{vecinos}$ es el número de enfriamientos a realizar.  

\subsection{Búsqueda Tabú}

\small{\texttt{\input{BT}}}
\normalsize\\

El criterio de aspiración en este caso consiste en tener mejor tasa de clasificación que la mejor
solución hasta el momento. La tenencia tabú es de $n/3$ con $n$ el número de características totales.

\subsection{Búsqueda Tabú extendida}

\small{\texttt{\input{BText}}}
\normalsize\\

La probabilidad de diversificación considerada en este caso es la misma que la intensificación, 0.25.
La tenencia tabú es de $n/3$ con $n$ el número de características totales.

\section{Algoritmo de comparación: SFS}
\small{\texttt{\input{SFS}}}

Partiendo de una selección de características vacía (máscara nula), va añadiendo a cada paso la característica
de las no escogidas hasta el momento que maximiza la tasa de clasificación añadiéndola a la solución, hasta
que la característica escogida no mejore a la mejor solución hasta el momento

\section{Implementación de la práctica}
Para la implementación de la práctica, se ha optado por usar el lenguaje de programación R. 

El clasificador \texttt{3nn} leaving one out empleado es el incluido en el paquete \texttt{class}, de nombre
\texttt{knn.cv}. Para su uso, se le pasa como argumento el número de vecinos a considerar (3). El argumento 
\texttt{use.all=TRUE} indica que en caso de empate considere todas las etiquetas de las instancias con distancias 
iguales a la mayoritaria (en este caso las tres), y escoja la etiqueta mayoritaria de entre todas. 

A la hora del desarrollo de la práctica se ha planteado el problema de que en caso de empate aún intentando 
resolver los conflictos de la manera anteriormente descrita, el clasificador escoge la etiqueta que
asignar de manera aleatoria. Esto lleva a problemas diversos, como que dos llamadas sucesivas con los mismos
parámetros a la función \texttt{tasa.clas}, que es la función objetivo de nuestra práctica, podrían producir resultados 
distintos. O incluso que si inicializaramos las soluciones iniciales de otra metaheurística, a saber, por ejemplo la
Búsqueda Local, con la del algoritmo greedy, a pesar de que esta no sustituye a la mejor solución hasta el momento a 
no ser que encuentre otra con mayor tasa de clasificación, como después esta máscara se aplica al conjunto 
\texttt{test} y se le haya la tasa de clasificación, podríamos encontrarnos que la SFS produce mejores tasas
de clasificación que la Búsqueda Local para un mismo conjunto de entrenamiento y con una misma semilla aleatoria, por
el número distinto de llamadas al generador de números aleatorios que hace cada algoritmo.

Para normalizar los datasets se ha creado una función (\texttt{normalize(data.frame)}) que los limpia de columnas con
un único valor, establece los nombres de los atributos todos a minúsculas, reordena los atributos del dataset para que
la clase sea el último de todos, y hace una transformación con las columnas para que todos los valores estén comprendidos
entre 0 y 1.

Se describe a continuación un esquema de los ficheros de código:
\begin{itemize}
 \item \texttt{\blue{main.r}}: de arriba a abajo, carga los paquetes necesarios, incluye el código fuente de otros ficheros
  (\texttt{\blue{aux.r, NN3.r, SFS.r, BL.r,}\ldots}) y lee los parámetros necesarios, entre ellos las semillas aleatorias
  (12345678, 23456781, 34567812, 45678123, 56781234) del fichero \texttt{params.r}
  
  Se ejecuta la función \texttt{cross.eval(algoritmo)}, guardando los resultados en la lista \texttt{algoritmo.results}
  Esta lista contendrá 3 dataframes con los datos del 5x2 cross validation, uno por dataset, con 10 filas cada uno 
  y columnas las tasas de clasificación de test y train, la tasa de reducción y el tiempo de ejecución. 
  Incluye también 3 datasets más con la media de los datos anteriores para cada conjunto de datos.
 
 \item \texttt{\blue{aux.r}}: contiene las implementaciones de la función de normalización de datasets, la función de
 particionado de \texttt{data.frames}, la función objetivo \texttt{tasa.clas} y la función \texttt{cross.eval}
 descrita arriba.
 
 \item \texttt{\blue{NN3.r, SFS.r, BL.r, ES.r, }\ldots}: contiene la implementación de los algoritmos de nombre 
 homónimo.
 
 \item \texttt{params.r}: fichero del que se leen los parámetros:
  \begin{itemize}
    \item \texttt{semilla}: vector de semillas aleatorias para poder reproducir los análisis hechos.
    \item \texttt{ES.coef.max.vecinos, ES.coef.max.exitos, ES.mu, ES.phi, \\BT.max.vecinos, BT.coef.tenencia.tabu,\ldots}:
    son parámetros propios de cada metaheurística, descritos en dicho fichero encima de cada bloque de parámetros.
    Por defecto están seteados para que se empleen los valores aportados en la documentación de la práctica.
  \end{itemize}
 \end{itemize}
 
 Para verificar los datos aportados para el algoritmo \texttt{algx}, a saber, basta ejecutar todo el fichero \texttt{main.r}
 hasta justo antes de la sección \textit{Obtención de resultados}. A continuación, si se ejecuta la línea 
 \texttt{algx.results <- cross.eval(algx)} se obtienen almacenados en una lista los valores de tasas y tiempos de ejecución
 aportados en la presente memoria.
\end{document}