\documentclass[a4paper,11pt]{article}
% Símbolo del euro
\usepackage[gen]{eurosym}
% Codificación
\usepackage[utf8]{inputenc}
% Idioma
\usepackage[spanish]{babel} % English language/hyphenation
\selectlanguage{spanish}
% Hay que pelearse con babel-spanish para el alineamiento del punto decimal
\decimalpoint
\usepackage{dcolumn}
\newcolumntype{d}[1]{D{.}{\esperiod}{#1}}
\makeatletter
\addto\shorthandsspanish{\let\esperiod\es@period@code}
\makeatother

\usepackage[usenames,dvipsnames]{color} % Coloring code

\usepackage{csvsimple}
\usepackage{adjustbox}
\newsavebox\ltmcbox


% Para matrices
\usepackage{amsmath}

% Símbolos matemáticos
\usepackage{amssymb}
\let\oldemptyset\emptyset
\let\emptyset\varnothing

% Hipervínculos
\usepackage{url}

\usepackage[section]{placeins} % Para gráficas en su sección.
\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\newenvironment{allintypewriter}{\ttfamily}{\par}
\setlength{\parindent}{0pt}
\parskip=8pt
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default


% Imágenes
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{wrapfig} % Allows in-line images



% Márgenes
\usepackage{geometry}
 \geometry{
 a4paper,
 total={210mm,297mm},
 left=30mm,
 right=30mm,
 top=25mm,
 bottom=25mm,
 }


% Referencias
\usepackage{fncylab}
\labelformat{figure}{\textit{\figurename\space #1}}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}


\makeatletter
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography
\newcommand{\imagent}[4]{
  \begin{wrapfigure}{#4}{0.7\textwidth}
    \begin{center}
    \includegraphics[width=0.7\textwidth]{#1}
    \end{center}
    \caption{#3}
    \label{#4}
  \end{wrapfigure}
}


\newcommand{\imagen}[4]{
  \begin{minipage}{\linewidth}
    \centering
    \includegraphics[width=#4\textwidth]{#1}
    \captionof{figure}{#2}
    \label{#3}
  \end{minipage} 
}

\newcommand{\imgn}[3]{
  \begin{minipage}{\linewidth}
    \centering
    \includegraphics[width=#3\textwidth]{#1}
    \captionof{figure}{#2}
  \end{minipage} 
}

% Ejemplo de parámetro: ILS.r
\newcommand{\hrefr}[1]{
\href{../bin/#1}{#1}
}

%Customize enumerate tag
\usepackage{enumitem}
%Sections don't get numbered
%\setcounter{secnumdepth}{0}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
% Modified by: NCordon (https://github.com/NCordon)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title_page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------
\textsc{\LARGE Universidad de Granada}\\[1.5cm]
\textsc{\Large Metaheaurísticas}\\[0.5cm] 

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------
\bigskip
\HRule \\[0.4cm]
{ \huge \bfseries Práctica II}\\[0.4cm] % Title of your document
{ \huge \bfseries Selección de características}\\
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{\textwidth}
\begin{center} \large
\emph{Búsqueda Multiarranque Básica}\\
\emph{GRASP}\\
\emph{Búsqueda Local Reiterada(ILS)}\\
\end{center}
\end{minipage}

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\begin{center}
\includegraphics[width=8cm]{../data/ugr.jpg}
\end{center}
%----------------------------------------------------------------------------------------

\begin{minipage}{\textwidth}
\begin{center} \large
Ignacio Cordón Castillo, 25352973G\\
\url{nachocordon@correo.ugr.es}\\
\ \\
$4^{\circ}$ Doble Grado Matemáticas Informática\\
Grupo Prácticas Viernes
\end{center}
\end{minipage}


\vspace{\fill}% Fill the rest of the page with whitespace
\large\today
\end{titlepage}  

\newpage
\tableofcontents
\newpage
% Examples of inclussion of images
%\imagent{ugr.jpg}{Logo de prueba}{ugr}
%\imagen{ugr.jpg}{Logo de prueba}{ugr2}{size relative to the \textwidth}

\section{Descripción del problema}
Dado un \textit{dataset} de instancias ya clasificadas, con una serie de atributos, se pretende comparar las distintas 
metaheaurísticas disponibles para comprobar cuál produce el conjunto de atributos que sirven para obtener una mayor 
tasa de clasificación (número de instancias bien clasificadas sobre el total) usando un clasificador de instancias.
En otras palabras, si tenemos $p$ atributos o características, el número total de subconjuntos de características que podemos
escoger es $2^p$. Cada uno de esos conjuntos o selecciones de características tendrá una tasa de clasificación asociada para
el clasificador que hemos escogido. Como este problema cuando $p$ es muy grande es inabordable por fuerza bruta, se aplican metaheurísticas para encontrar la mejor selección de características posible de entre esas $2^p$ posibilidades.

Se considera la tasa de clasificación en el problema usando un clasificador \textit{3-knn} leaving one-out. Para cada 
instancia de un conjunto, toma las 3 más cercanas usando la distancia euclídea entre sus atributos, y etiqueta la nueva
instancia en función de la etiqueta mayoritaria de entre esas tres. Se efectúan 5 particiones al 50\% estratificadas
por clase en \textit{train - test}, de modo que la metaheurística proporcionará un conjunto de atributos para el conjunto de
entrenamiento, y se calculará la tasa de clasificación que produce sobre el conjunto de prueba para el \textit{3-knn} dicho
conjunto de atributos. El proceso se repite intercambiando los conjuntos de entrenamiento y de test. La calidad de la 
metaheaurística/algoritmo se calculará como la media de todas las tasas de clasificación obtenidas sobre el conjunto test
(10 en total). Otras medidas que se tendrán en cuenta a la hora de evaluar la bondad de un algoritmo empleado serán:
\begin{itemize}
 \item Tasa de reducción: Porcentaje de características que ha eliminado la máscara sobre el total que podía 
 seleccionar. Mejor cuanto más alta. En nuestros resultados lo hemos expresado como un tanto por uno.
 \item Tiempo de ejecución: Tiempo en segundos que tarda el algoritmo en devolver un conjunto de características.
 Se busca el menor tiempo de ejecución posible.
\end{itemize}


La tasa de clasificación del clasificador se mide (en tanto por uno) como: $$tasa\: clasificacion = \frac{instancias\: 
bien\: clasificadas}{total\: instancias}$$

La representación usada es la binaria (1 o 0 por característica), donde tenemos un vector de tamaño $n$, con $n$ el número 
de atributos (exceptuando la clase), y la metaheaurística/algoritmo ha seleccionado el atributo si y solo si lo ha marcado 
a 1. A una representación de esta forma, la denominamos máscara: $$ mask =\begin{matrix} (0 & 1\ldots 1 & 1 & 0\ldots) 
\end{matrix}$$

\newpage
\section{Descripción elementos comunes de los algoritmos}
Los algoritmos considerados tienen las siguientes componentes:

\begin{itemize} 
\item \textbf{Esquema de representación:} se usan máscaras, sucesiones de unos y ceros de tanta longitud como atributos haya,
exceptuando la clase, donde un 1 en la posición $i-$ésima indica que esa característica se ha escogido, y un $0$ que no.

\item \textbf{Función objetivo}: la función a maximizar será la tasa de clasificación explicada arriba usando el clasificador
3-knn con la selección de características indicada por la máscara.\\

\small\texttt{\input{tasa_clasificacion}}
\normalsize

\item \textbf{Generación de solución aleatoria inicial: }
  \begin{itemize}
   \item BMB: En la BMB se generarán 25 soluciones aleatorias sobre las que se aplicará búsqueda local para refinarlas.
   En el siguiente pseudocódigo \texttt{max\_arranques} vale 25, y $n$ es el número de características del dataset.\\
   
   \small\texttt{\input{BMB_gen_init}}
   \normalsize
   
   \item ILS: Se generará una solución inicial aleatoria mediante el procedimiento descrito a continuación, con $n$ el
   número de características del dataset.
   
   \small\texttt{\input{ILS_gen_init}}
   \normalsize
    
  \end{itemize}


\item \textbf{Algoritmo Búsqueda Local (BL)} empleado:
  
  El operador de generación de vecino usado ha sido:
  \footnote{En R, puesto que estamos manejando un vector de 0 y 1, el operador \texttt{flip} puede explicitarse como
  \texttt{mask[j]} = \texttt{!mask[j]}}
  
  \small\texttt{\input{flip}}
  \normalsize
  
  
  El algoritmo, propiamente dicho, que se ha empleado ha sido:\\
  
  \small\texttt{\input{BL}}
  
  Se realizan 15000 iteraciones en el bucle principal de la búsqueda local.

\item \textbf{Número de multiarranques}: se empleará la búsqueda local sobre 25 máscaras en el BMB, GRASP e ILS.

\end{itemize}


\section{Profundización en los algoritmos}
Se incluyen a continuación una descripción de cada metaheurística empleada junto a un pseudocódigo de las mismas.

Sea a partir de aquí $n$ el número de atributos de los respectivos \textit{datasets}.
\subsection{Búsqueda multiarranque básica}
Puesto que \texttt{max\_arranques} vale 25, se generan 25 soluciones iniciales, se les aplica búsqueda local, y nos quedamos
con la que maximiza el \textit{score}. En este caso, \texttt{alpha} vale 0.3\\

\small{\texttt{\input{BMB}}}
\normalsize

\subsection{GRASP}
La solución inicial se generará mediante un \textit{greedy} aleatorizado, y se refinará mediante
la búsqueda local, quedándonos con la mejor de entre 25 generadas.\\
   
\small\texttt{\input{GRASP_gen_init}}
\normalsize

Se generan 25 soluciones greedy aleatorizadas (ya que en este caso \texttt{max\_arranques} vale 25), se les aplica búsqueda
local, y nos quedamos con la que maximiza el \textit{score}.\\

\small{\texttt{\input{GRASP}}}
\normalsize

\subsection{Búsqueda Local Reiterada (ILS)}
Se genera una solución inicial aleatoria mediante el procedimiento descrito anteriormente, y sobre esa se
aplica búsqueda local, y el resto de iteraciones del algoritmo (24), se efectúa el mismo procedimiento sobre la mejor solución
mutada. En este caso \texttt{prob\_mutacion} vale 0.1.\\

\small{\texttt{\input{ILS}}}
\normalsize

\section{Algoritmo de comparación: SFS}
\small{\texttt{\input{SFS}}}

Partiendo de una selección de características vacía (máscara nula), va añadiendo a cada paso la característica
de las no escogidas hasta el momento que maximiza la tasa de clasificación añadiéndola a la solución, hasta
que la característica escogida no mejore a la mejor solución hasta el momento

\section{Implementación de la práctica}
Para la implementación de la práctica, se ha optado, al igual que en la primera práctica de trayectorias simples,
por usar el lenguaje de programación R, reutilizando toda la lectura de ficheros ya implementada para la primera práctica
y todas las funciones auxiliares.

El clasificador \texttt{3nn} leaving one out empleado es el incluido en el paquete \texttt{class}, de nombre
\texttt{knn.cv}. Para su uso, se le pasa como argumento el número de vecinos a considerar (3). El argumento 
\texttt{use.all=TRUE} indica que en caso de empate considere todas las etiquetas de las instancias con distancias 
iguales a la mayoritaria (en este caso las tres), y escoja la etiqueta mayoritaria de entre todas. 

Ya se comentó en la primera práctica la desventaja de usar este paquete de R en caso de triple empate por el hecho de
escoger la etiqueta que asignar de manera aleatoria y dar lugar esto a sesgo en distintas llamadas.

Se emplea de nuevo la función (\texttt{normalize(data.frame)}) que limpia los \textit{datasets} de columnas con
un único valor, establece los nombres de los atributos todos a minúsculas, reordena los atributos del dataset para que
la clase sea el último de todos, y hace una transformación con las columnas para que todos los valores estén comprendidos
entre 0 y 1.

Se describe a continuación un esquema de los ficheros de código:
\begin{itemize}
 \item \hrefr{main.r}: de arriba a abajo, carga los paquetes necesarios, incluye el código fuente de otros ficheros
  (\hrefr{aux.r}, \hrefr{NN3.r}, \hrefr{SFS.r}, \hrefr{BL.r},\ldots) y lee los parámetros necesarios como las 
  semillas aleatorias (12345678, 23456781, 34567812, 45678123, 56781234), desde el fichero \hrefr{params.r}
  
  Se ejecuta la función \texttt{cross.eval(algoritmo)}, que almacena los resultados de la ejecución en la lista
  \texttt{algoritmo.results}. Esta lista contendrá 3 dataframes con los datos del 5x2 cross validation, uno por dataset, 
  con 10 filas cada uno  y columnas las tasas de clasificación de test y train, la tasa de reducción y el tiempo de 
  ejecución. Incluye también 3 datasets más con la media de los datos anteriores para cada conjunto de datos. La implementación
  de la función \texttt{cross.eval} ha sido revisada para esta práctica, aunque su utilidad y su forma de uso sigue
  siendo la misma.
 
 \item \hrefr{aux.r}: contiene las implementaciones de la función de normalización de datasets, la función de
 particionado de \texttt{data.frames}, la función objetivo \texttt{tasa.clas} y la función \texttt{cross.eval}
 descrita arriba.
 
 \item \hrefr{BL.r}, \hrefr{BMB.r}, \hrefr{GRASP.r}, \hrefr{ILS.r}: contiene la implementación de los algoritmos de Búsqueda Local (BL), Búsqueda 
 Multiarranque Básica(BMB), Búsqueda Multiarranque GRASP(GRASP) y Búsqueda Local Reiterada(ILS), respectivamente. 
 Asimismo también podemos encontrar los inicializadores de máscaras aleatorias (\texttt{random.init}), en \texttt{BL.r};
 y de máscaras greedy aleatorizadas (\texttt{random.greedy.init}), este en \texttt{GRASP.r}
 
 \item \hrefr{params.r}: fichero del que se leen los parámetros:
  \begin{itemize}
    \item \texttt{semilla}: vector de semillas aleatorias para poder reproducir los análisis hechos.
    \item \texttt{max\_eval}: máximo de evaluaciones de la búsqueda local. Seteado a 15000.
    \item \texttt{BMB.num.sols.init, GRASP.num.sols.init, ILS.num.sols.init}: número de rearranques del algoritmo homónimo.
    Por defecto configurados a 25.
    \item \texttt{GRASP.alpha}: tolerancia para aceptar, en el algoritmo GRASP, una solución en la lista de candidatos 
    respecto a la mejor solución en esa iteración. Por defecto, $\alpha=0.3$
    \item \texttt{ILS.coef.mutacion}: multiplicado por $n$ (número de características en total), es el número de coeficientes
    de una máscara que se mutarán en la Búsqueda Local Reiterada. En nuestro caso, 0.1 por defecto (un 10\%).
  \end{itemize}
 \end{itemize}
 
 Para verificar los datos aportados para el algoritmo \texttt{algx}, a saber, basta ejecutar todo el fichero \texttt{main.r}
 hasta justo antes de la sección \textit{Obtención de resultados}. A continuación, si se ejecuta la línea 
 \texttt{algx.results <- cross.eval(algx)} se obtienen almacenados en una lista los valores de tasas y tiempos de ejecución
 aportados en la presente memoria. 
 
 Para trabajar correctamente, el working path debe estar seteado a la carpeta de códigos fuente. Se puede consultar el 
 valor actual mediante \texttt{getwd()} y setearlo mediante \texttt{setwd(path)}
 
 Cuando se cambia algo en algún algoritmo o en \texttt{params.r} hay que recargar en \texttt{main.r}
 la línea del \texttt{source(file=...)} correspondiente.
 
 \section{Experimentos y análisis de resultados}
 \subsection{Tablas de resultados}
 \begin{table}[H]	
  \caption{Resultados del 3NN}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhythmia}}} \\ \hline
  & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{Partición 1-1} & 95.78947 & 97.53521 & 0.00000 & 0.00000 & 65.00000 & 66.66667 & 0.00000 & 0.00000 & 65.46392 & 65.62500 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 1-2} & 97.53521 & 95.78947 & 0.00000 & 0.00000 & 66.11111 & 67.77778 & 0.00000 & 0.00000 & 65.62500 & 65.97938 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 2-1} & 97.19298 & 95.77465 & 0.00000 & 0.00000 & 72.22222 & 64.44444 & 0.00000 & 0.00000 & 62.88660 & 61.45833 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 2-2} & 95.77465 & 97.19298 & 0.00000 & 0.00000 & 63.33333 & 70.00000 & 0.00000 & 0.00000 & 63.02083 & 63.91753 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 3-1} & 96.14035 & 96.47887 & 0.00000 & 0.00000 & 72.77778 & 65.00000 & 0.00000 & 0.00000 & 62.37113 & 64.06250 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 3-2} & 96.47887 & 96.14035 & 0.00000 & 0.00000 & 63.33333 & 75.00000 & 0.00000 & 0.00000 & 63.54167 & 62.88660 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 4-1} & 95.43860 & 97.88732 & 0.00000 & 0.00000 & 74.44444 & 66.66667 & 0.00000 & 0.00000 & 64.94845 & 62.50000 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 4-2} & 97.88732 & 95.43860 & 0.00000 & 0.00000 & 64.44444 & 72.77778 & 0.00000 & 0.00000 & 61.45833 & 62.88660 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 5-1} & 96.49123 & 96.83099 & 0.00000 & 0.00000 & 63.33333 & 68.33333 & 0.00000 & 0.00000 & 61.85567 & 61.45833 & 0.00000 & 0.00000 \\ \hline
  \textbf{Partición 5-2} & 96.83099 & 96.49123 & 0.00000 & 0.00000 & 67.77778 & 65.55556 & 0.00000 & 0.00000 & 60.41667 & 62.37113 & 0.00000 & 0.00000 \\ \hline
  \textbf{Media} & 96.55597 & 96.55597 & 0.00000 & 0.00000 & 67.27778 & 68.22222 & 0.00000 & 0.00000 & 63.15883 & 63.31454 & 0.00000 & 0.00000 \\ \hline
  \textbf{Desv.Típica} & 0.76434 & 0.76434 & 0.00000 & 0.00000 & 4.09343 & 3.26599 & 0.00000 & 0.00000 & 1.66035 & 1.48907 & 0.00000 & 0.00000 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{NN3}
  \end{table}
  
  \begin{table}[H]	
  \caption{Resultados del SFS}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhytmia}}} \\ \hline
  \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{Partición 1-1} & 91.92982 & 97.53521 & 0.86667 & 0.15400 & 63.88889 & 70.55556 & 0.88889 & 1.01200 & 64.94845 & 75.00000 & 0.98419 & 1.84000 \\ \hline
  \textbf{Partición 1-2} & 95.77465 & 97.89474 & 0.80000 & 0.25600 & 65.00000 & 68.33333 & 0.87778 & 1.29800 & 75.00000 & 78.35052 & 0.98419 & 1.98900 \\ \hline
  \textbf{Partición 2-1} & 97.19298 & 97.88732 & 0.86667 & 0.15200 & 64.44444 & 66.66667 & 0.93333 & 0.57300 & 64.94845 & 76.56250 & 0.98419 & 1.95300 \\ \hline
  \textbf{Partición 2-2} & 94.01408 & 97.19298 & 0.80000 & 0.26600 & 62.22222 & 69.44444 & 0.87778 & 1.13400 & 73.43750 & 71.13402 & 0.98419 & 2.22600 \\ \hline
  \textbf{Partición 3-1} & 94.38596 & 95.77465 & 0.93333 & 0.09700 & 66.66667 & 66.11111 & 0.88889 & 1.02800 & 72.16495 & 80.20833 & 0.98024 & 2.34900 \\ \hline
  \textbf{Partición 3-2} & 91.54930 & 96.14035 & 0.90000 & 0.14500 & 62.22222 & 74.44444 & 0.88889 & 1.20200 & 67.70833 & 74.22680 & 0.98024 & 2.20000 \\ \hline
  \textbf{Partición 4-1} & 94.03509 & 97.88732 & 0.90000 & 0.12000 & 71.66667 & 72.22222 & 0.88889 & 1.31100 & 74.22680 & 76.04167 & 0.98024 & 2.02000 \\ \hline
  \textbf{Partición 4-2} & 92.25352 & 94.38596 & 0.90000 & 0.11700 & 65.55556 & 77.22222 & 0.90000 & 0.87400 & 67.70833 & 76.80412 & 0.98419 & 2.44800 \\ \hline
  \textbf{Partición 5-1} & 94.73684 & 95.77465 & 0.86667 & 0.15500 & 58.33333 & 75.55556 & 0.91111 & 0.76600 & 67.52577 & 75.52083 & 0.98419 & 2.30900 \\ \hline
  \textbf{Partición 5-2} & 90.49296 & 96.49123 & 0.86667 & 0.15300 & 65.00000 & 67.22222 & 0.90000 & 0.99900 & 70.83333 & 74.74227 & 0.98814 & 1.33000 \\ \hline
  \textbf{Media} & 93.63652 & 96.69644 & 0.87000 & 0.16150 & 64.50000 & 70.77778 & 0.89556 & 1.01970 & 69.85019 & 75.85911 & 0.98340 & 2.06640 \\ \hline
  \textbf{Desv.Típica} & 1.95851 & 1.12301 & 0.04069 & 0.05315 & 3.26268 & 3.72844 & 0.01587 & 0.22233 & 3.57073 & 2.31592 & 0.00237 & 0.30695 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{SFS}
  \end{table}
  
  \begin{table}[H]
  \caption{Resultados del BMB}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhytmia}}} \\ \hline
  \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{Partición 1-1} & 94.03509 & 98.94366 & 0.40000 & 4.89100 & 62.77778 & 72.22222 & 0.58889 & 24.48300 & 66.49485 & 68.75000 & 0.47431 & 559.55700 \\ \hline
  \textbf{Partición 1-2} & 96.12676 & 98.24561 & 0.36667 & 5.21200 & 67.22222 & 64.44444 & 0.48889 & 24.28400 & 65.10417 & 71.64948 & 0.58893 & 551.05100 \\ \hline
  \textbf{Partición 2-1} & 95.43860 & 97.53521 & 0.53333 & 6.58300 & 68.88889 & 72.22222 & 0.55556 & 23.17700 & 62.88660 & 69.79167 & 0.56917 & 459.46600 \\ \hline
  \textbf{Partición 2-2} & 94.01408 & 98.94737 & 0.56667 & 6.90500 & 62.77778 & 76.11111 & 0.46667 & 21.58600 & 64.58333 & 66.49485 & 0.49802 & 472.28700 \\ \hline
  \textbf{Partición 3-1} & 96.14035 & 97.88732 & 0.50000 & 5.03300 & 71.66667 & 70.55556 & 0.51111 & 21.15200 & 64.43299 & 70.83333 & 0.45850 & 636.12600 \\ \hline
  \textbf{Partición 3-2} & 94.36620 & 98.24561 & 0.46667 & 5.36500 & 66.66667 & 79.44444 & 0.42222 & 23.49600 & 63.54167 & 68.04124 & 0.56522 & 454.29100 \\ \hline
  \textbf{Partición 4-1} & 94.73684 & 98.94366 & 0.46667 & 4.78800 & 68.33333 & 68.88889 & 0.60000 & 21.06900 & 64.94845 & 67.18750 & 0.50988 & 539.35300 \\ \hline
  \textbf{Partición 4-2} & 95.42254 & 97.54386 & 0.50000 & 4.91600 & 66.66667 & 74.44444 & 0.47778 & 20.57700 & 65.10417 & 70.61856 & 0.54941 & 480.48400 \\ \hline
  \textbf{Partición 5-1} & 95.43860 & 97.88732 & 0.46667 & 5.01900 & 66.11111 & 72.22222 & 0.51111 & 19.70900 & 62.37113 & 65.62500 & 0.54941 & 507.68300 \\ \hline
  \textbf{Partición 5-2} & 95.07042 & 98.24561 & 0.46667 & 4.56000 & 65.55556 & 66.11111 & 0.51111 & 21.76900 & 59.89583 & 68.04124 & 0.57312 & 509.55800 \\ \hline
  \textbf{Media} & 95.07895 & 98.24252 & 0.47333 & 5.32720 & 66.66667 & 71.66667 & 0.51333 & 22.13020 & 63.93632 & 68.70329 & 0.53360 & 516.98560 \\ \hline
  \textbf{Desv.Típica} & 0.73824 & 0.52161 & 0.05538 & 0.74172 & 2.54588 & 4.25281 & 0.05230 & 1.54661 & 1.76058 & 1.88678 & 0.04286 & 53.27163 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{BMB}
  \end{table}

  \begin{table}[H]
  \caption{Resultados del GRASP}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhytmia}}} \\ \hline
  \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{Partición 1-1} & 95.08772 & 98.94366 & 0.73333 & 6.39000 & 59.44444 & 72.77778 & 0.86667 & 31.34700 & 69.07216 & 77.60417 & 0.94071 & 66.54200 \\ \hline
  \textbf{Partición 1-2} & 94.36620 & 98.59649 & 0.66667 & 7.65700 & 65.00000 & 74.44444 & 0.83333 & 27.10800 & 70.83333 & 81.95876 & 0.93281 & 86.96500 \\ \hline
  \textbf{Partición 2-1} & 95.08772 & 98.23944 & 0.76667 & 6.24400 & 62.22222 & 71.66667 & 0.86667 & 27.14100 & 69.07216 & 80.72917 & 0.94862 & 84.36400 \\ \hline
  \textbf{Partición 2-2} & 96.47887 & 98.94737 & 0.66667 & 7.48500 & 68.88889 & 78.33333 & 0.81111 & 30.23100 & 71.35417 & 78.35052 & 0.95257 & 80.98800 \\ \hline
  \textbf{Partición 3-1} & 96.49123 & 98.23944 & 0.80000 & 6.38600 & 71.11111 & 73.33333 & 0.86667 & 26.74900 & 67.01031 & 82.29167 & 0.90119 & 93.01400 \\ \hline
  \textbf{Partición 3-2} & 95.42254 & 98.24561 & 0.80000 & 6.26100 & 63.88889 & 77.77778 & 0.84444 & 31.06500 & 75.00000 & 77.31959 & 0.92885 & 64.86900 \\ \hline
  \textbf{Partición 4-1} & 95.08772 & 99.29577 & 0.80000 & 7.12200 & 72.77778 & 72.77778 & 0.87778 & 30.86800 & 73.19588 & 77.60417 & 0.92490 & 71.93300 \\ \hline
  \textbf{Partición 4-2} & 98.23944 & 97.89474 & 0.70000 & 6.32900 & 66.11111 & 77.22222 & 0.85556 & 26.87700 & 66.14583 & 79.89691 & 0.95652 & 73.92300 \\ \hline
  \textbf{Partición 5-1} & 94.38596 & 97.88732 & 0.73333 & 6.93500 & 65.00000 & 79.44444 & 0.82222 & 29.86400 & 72.68041 & 83.33333 & 0.91304 & 78.73700 \\ \hline
  \textbf{Partición 5-2} & 92.60563 & 98.59649 & 0.66667 & 6.43600 & 73.88889 & 69.44444 & 0.83333 & 26.30000 & 73.95833 & 81.95876 & 0.91700 & 85.65900 \\ \hline
  \textbf{Media} & 95.32530 & 98.48863 & 0.73333 & 6.72450 & 66.83333 & 74.72222 & 0.84778 & 28.75500 & 70.83226 & 80.10471 & 0.93162 & 78.69940 \\ \hline
  \textbf{Desv.Típica} & 1.43387 & 0.44607 & 0.05375 & 0.50617 & 4.46558 & 3.12546 & 0.02111 & 1.97036 & 2.81395 & 2.14136 & 0.01723 & 8.75598 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{GRASP}
  \end{table}

  
  \begin{table}[H]
  \caption{Resultados del ILS}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhytmia}}} \\ \hline
  \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{Partición 1-1} & 96.84211 & 98.94366 & 0.50000 & 4.77400 & 62.22222 & 68.88889 & 0.57778 & 21.96400 & 67.01031 & 69.79167 & 0.48617 & 547.73100 \\ \hline
  \textbf{Partición 1-2} & 95.42254 & 98.59649 & 0.66667 & 4.78400 & 61.11111 & 63.33333 & 0.51111 & 23.65400 & 65.10417 & 69.07216 & 0.50198 & 557.80000 \\ \hline
  \textbf{Partición 2-1} & 97.54386 & 97.88732 & 0.46667 & 5.23500 & 70.55556 & 68.33333 & 0.41111 & 24.52000 & 65.46392 & 72.91667 & 0.49407 & 570.61600 \\ \hline
  \textbf{Partición 2-2} & 96.47887 & 99.29825 & 0.56667 & 4.70900 & 65.55556 & 73.88889 & 0.48889 & 25.60200 & 61.45833 & 69.07216 & 0.49012 & 549.34300 \\ \hline
  \textbf{Partición 3-1} & 96.84211 & 98.23944 & 0.53333 & 5.49400 & 71.66667 & 67.22222 & 0.51111 & 26.67000 & 63.40206 & 70.31250 & 0.48617 & 549.35500 \\ \hline
  \textbf{Partición 3-2} & 95.07042 & 98.59649 & 0.43333 & 4.51000 & 66.66667 & 77.22222 & 0.51111 & 20.65300 & 62.50000 & 65.46392 & 0.52174 & 512.64700 \\ \hline
  \textbf{Partición 4-1} & 94.73684 & 99.29577 & 0.43333 & 4.94000 & 71.66667 & 70.00000 & 0.52222 & 21.75600 & 65.46392 & 67.18750 & 0.52174 & 608.64800 \\ \hline
  \textbf{Partición 4-2} & 96.83099 & 97.54386 & 0.40000 & 5.37500 & 65.00000 & 73.88889 & 0.54444 & 20.78000 & 62.50000 & 68.04124 & 0.54150 & 552.57200 \\ \hline
  \textbf{Partición 5-1} & 96.84211 & 97.88732 & 0.26667 & 5.98500 & 66.11111 & 74.44444 & 0.45556 & 21.68800 & 62.37113 & 71.35417 & 0.51779 & 474.18500 \\ \hline
  \textbf{Partición 5-2} & 94.36620 & 98.59649 & 0.50000 & 4.97300 & 67.22222 & 66.66667 & 0.46667 & 19.75400 & 67.70833 & 69.58763 & 0.54545 & 430.18100 \\ \hline
  \textbf{Media} & 96.09761 & 98.48851 & 0.47667 & 5.07790 & 66.77778 & 70.38889 & 0.50000 & 22.70410 & 64.29822 & 69.27996 & 0.51067 & 535.30780 \\ \hline
  \textbf{Desv.Típica} & 1.03913 & 0.56804 & 0.10116 & 0.42146 & 3.46767 & 4.09795 & 0.04472 & 2.17755 & 2.03471 & 1.98776 & 0.02105 & 48.24853 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{ILS}
  \end{table}
  
  
  \begin{table}[H]
  \caption{Resultados globales}
  \begin{adjustbox}{width=1.1\textwidth}
  \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
  \multicolumn{1}{|l|}{} & \multicolumn{ 4}{c|}{\textbf{\textit{Wdbc}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Movement\_Libras}}} & \multicolumn{ 4}{c|}{\textbf{\textit{Arrhytmia}}} \\ \hline
  \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas test}}} & \multicolumn{1}{c|}{\textbf{\textit{\% clas train}}} & \multicolumn{1}{c|}{\textbf{\textit{tasa red}}} & \multicolumn{1}{c|}{\textbf{T(s)}} \\ \hline
  \textbf{3-NN} & 96.55597 & 96.55597 & 0.00000 & 0.00000 & 67.27778 & 68.22222 & 0.00000 & 0.00000 & 63.15883 & 63.31454 & 0.00000 & 0.00000 \\ \hline
  \textbf{SFS} & 93.63652 & 96.69644 & 0.87000 & 0.16150 & 64.50000 & 70.77778 & 0.89556 & 1.01970 & 69.85019 & 75.85911 & 0.98340 & 2.06640 \\ \hline
  \textbf{BMB} & 95.07895 & 98.24252 & 0.47333 & 5.32720 & 66.66667 & 71.66667 & 0.51333 & 22.13020 & 63.93632 & 68.70329 & 0.53360 & 516.98560 \\ \hline
  \textbf{GRASP} & 95.32530 & 98.48863 & 0.73333 & 6.72450 & 66.83333 & 74.72222 & 0.84778 & 28.75500 & 70.83226 & 80.10471 & 0.93162 & 78.69940 \\ \hline
  \textbf{ILS} & 96.09761 & 98.48851 & 0.47667 & 5.07790 & 66.77778 & 70.38889 & 0.50000 & 22.70410 & 64.29822 & 69.27996 & 0.51067 & 535.30780 \\ \hline
  \end{tabular}
  \end{adjustbox}
  \label{all}
  \end{table}
  
  
  \subsection{Wdbc}
  
  Es un problema de clasificación binaria en un dataset de 30 atributos y 569 instancias.
   
  \imagen{../data/multi-restart/wdbc.png}{Tasas de clasificación en Wdbc}{wdbc}{0.7}
  
  \imagen{../data/multi-restart/wdbc_sfs_boxplot.png}{Boxplot del SFS}{wsfs}{1}
  
  \imagen{../data/multi-restart/wdbc_bmb_boxplot.png}{Boxplot del BMB}{wbmb}{1}
  
  \imagen{../data/multi-restart/wdbc_ils_boxplot.png}{Boxplot del ILS}{wils}{1}
  
  \imagen{../data/multi-restart/wdbc_grasp_boxplot.png}{Boxplot del GRASP}{wilsbp}{1}
  
  El mejor algoritmo para seleccionar características en este caso es el 3NN. Vuelve a ocurrir lo que en las metaheurísticas
  de trayectorias, ya que el \textit{vecino más cercano} funciona muy bien en poca dimensionalidad, al aproximar muy bien
  el clasificador de Bayes, que es el que menor error probabilístico comete.
  
  El que más se le acerca es el ILS, aunque tiene un porcentaje de reducción inferior al 50\%. Si comparamos por ejemplo el
  boxplot del SFS (\ref{wsfs}) con el del ILS (\ref{wils}), observamos que a pesar de que ambos tienen una reducción similar, 
  ILS incluye algunos atributos cuyos rangos intercuartílicos para las dos clases son disjuntos y que en BMB no están incluidos. 
  Puesto que el único componente que diferencia esas metaheaurísticas son las mutaciones, podemos concluir que resulta un proceso beneficioso
  para la búsqueda de soluciones. La explicación más plausible es que al mutar atributos, estamos introduciendo posbiles
  desmejoras en soluciones que dan lugar a que al aplicar búsqueda local se incuyan atributos que combinados con los que han
  provocado desmejoras por mutaciones, den lugar a una mejor solución de la que había.
  
  BMB y GRASP producen \textit{scores} muy similares. De hecho, en general, con tasas superiores al 95\%, todas las
  metaheurísticas se acercan a la solución del 3NN, pero siendo la tasa de reducción de este último nula, lo que dificulta
  mucho la interpretabilidad de los resultados si lo empleamos.
  
  En general no se observa \textit{overfiting} en la aplicación de las metaheurísticas.
  
  Dependiendo del objetivo del problema, podría resultar interesante aplicar GRASP en lugar de ILS, ya que los \textit{score}
  que producen ambos no difieren demasiado, pero GRASP produce una fuerte reducción en el número de características usadas.
  Ello se debe a que es fácil que una solución greedy aleatorizada que se está generando supere el umbral por el que se
  siguen añadiendo características, y por tanto, esta inicialización resulta muy positiva en tanto que las tasas de reducción,
  no solo en este dataset, sino también en los otros, es tremendamente buena.
  
  En cuanto a tiempo de ejecución, las tres metaheurísticas implementadas tardan alrededor de 5 segundos, lo que es un tiempo
  más que aceptable, pero que viene condicionado por la baja dimensionalidad del dataset que tratamos.
 
 
  \subsection{Movement libras}
  
  Se trata de un problema de clasficación multiclase (15 clases después de normalizar el dataset). 
  Contiene 360 instancias y 90 atributos.
  
  \imagen{../data/multi-restart/mlibras.png}{Tasas de clasificación en Movement Libras}{mlibras}{0.7}
  
  El algoritmo que mejor funciona en este caso es el 3NN, aunque las tasas de clasificación que se producen son muy similares
  entre BMB, GRASP, e ILS, al igual que sus tiempos de ejecución. GRASP sin embargo es el que más
  \textit{overfiting} realiza, siendo la media de clasificación en el conjunto de entrenamiento de un 74\% y en el de prueba
  de un 66\%. Sin embargo si analizamos el desglose en la tabla del GRASP(\ref{GRASP}), observamos que el resultado obtenido
  en la primera partición es el culpable de esto produciendo un \textit{overfiting} enorme.
  
  Por tanto lo único que nos puede hacer decidirnos por qué metaheurística es mejor de las 3 implementadas es la tasa de reducción,
  siendo mucho mejor en el GRASP, como ya se ha indicado en el análisis de wdbc. El otro algoritmo que también tiene una tasa
  de reducción muy buena es el SFS, pero con una menor tasa de clasificación que el SFS.
  
  Cabe destacar que los datos obtenidos son muy similares a los obtenidos en la práctica de trayectorias para las metaheurísticas
  de búsquedas tabú, enfriamiento simulado, \ldots. Si observamos \ref{mboxplot}, que es un boxplot de un 10\% de características
  aleatorias del dataset, vemos que en todas las variables hay muchas clases muy solapadas. 
  Por tanto, estamos ante un dataset duro de tratar, seguramente debido al alto número de clases. 
  De hecho, las tasas de clasificación que estamos manejando son incluso inferiores a las que obtenemos a veces sobre 
  Arrhythmia. En el caso de Movement Libras, los resultados que obtenemos probablemente se deban a la baja proporción instancias/clase.
  Es decir, disponemos de poca información para caracterizar cada clase. 
  
  \imagen{../data/multi-restart/mlibras_boxplot.png}{Boxplot de 10 \% de variables de Movement Libras}{mboxplot}{1}
  
  \subsection{Arrhythmia}
  
  Se trata de un problema de clasficación multiclase (5 clases después de normalizar el dataset). 
  Tiene 386 instancias y 253 atributos.
  
  \imagen{../data/multi-restart/arrhythmia.png}{Tasas de clasificación en Arrhythmia}{arrhythmia}{0.7}
  
  Observamos que en este problema el GRASP si es claramente superior a la BMB e ILS en cuanto a tasa de 
  clasificación, siendo superior hasta en 7 puntos porcentuales al BMB y aprox. 6 al ILS. Tiene muy buena tasa de
  reducción, y tanto la tasa de clasificación como de reducción son similares a las producidas por el SFS. Este último
  tiene un comportamiento tan bueno porque selecciona muy pocos atributos.
  
  Como se observa en el boxplot \ref{aboxplot} las clases también aparecen muy solapadas para cada atributo, aunque el menor
  número de clases determina que las tasas de clasificación que se obtienen sean un poquito mejores que con el triple de clases
  en Movement Libras.
  
  De hecho, de las 3 metaheaurísticas implementadas en tiempo, el GRASP es claramente superior, a pesar de realizar overfiting.
  Esto puede deberse a que como hemos expresado anteriormente, el greedy aleatorizado parece producir máscaras con un 
  número bajo de características seleccionadas, cualidad a tener en cuenta en este problema para las selecciones que se hacen,
  ya que los atributos exceden a las instancias con las que entrenamos, y tenemos poca información para calcular cada
  una de las clases.
  
  Por tanto, en un problema con tantísimas variables, debería primar la interpretabilidad de las soluciones, cualidad que
  conseguimos con el GRASP, además de la mejor tasa de clasificación. Un boxplot de las variables que selecciona el GRASP en
  este dataset puede consultarse en \ref{aboxplot}.
  
  \imagen{../data/multi-restart/arrhythmia_grasp_boxplot.png}{Boxplot de algunas características de Arrhythmia}{aboxplot}{1}
  
  \subsection{Notas finales}

  El GRASP ha dado muy buenos resultados en general, incluso aún no habiendo aumentado la tasa de clasificación en el 
  dataset Movement Libras, ya que en general las tasas de reducción que maneja son muy positivas. Asimismo, está dando
  unos resultados excelentes en Arrhythmia, donde parecía difícil encontrar un mecanismo que mejorase las soluciones de
  la anterior práctica, dada la gran multidimensionalidad del dataset.
  
  Excepto el GRASP, las otras dos metaheurísticas tienden a tener tasas de reducción de 0.5 por estar usando un generador
  de aleatorios con equiprobabilidad de generar un 0 o un 1, lo cual limita la calidad de las soluciones (por tener más 
  o menos características de la cuenta, fenómeno que se agrava bastante en el caso de un dataset que tiene 253 
  características, como es Arrhythmia).
  
  Como idea que ha surgido durante la realización de la práctica está el implementar una función \textit{stepwise} que para
  una máscara y un dataset dado, vaya quitando iterativamente las características seleccionadas que no reducen la tasa de
  clasificación, de manera que obtendríamos tasas de reducción superiores a las actuales pero manteniendo el nivel de 
  \textit{score} en clasificación. Es decir, podríamos obtener soluciones muy buenas en calidad e interpretabilidad. Se
  tratará de implementar esta función en futuras prácticas.
  
\end{document}